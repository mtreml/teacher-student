{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import caffe\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lmdb\n",
    "from caffe.proto import caffe_pb2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_mean = np.array([ 103.86496098,  116.78539062,  123.68693434])[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = caffe.Net('ResNet-50-deploy.prototxt',\n",
    "                'ResNet-50-model.caffemodel',\n",
    "                caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/imagenet/SegCompress'\n",
    "lmdb_env = lmdb.open('/imagenet/lmdb_scaled/training.lmdb/', readonly=True)\n",
    "net_batch_size = 32\n",
    "out_batch_size = 256*net_batch_size  # must be multiple of net_batch_size\n",
    "net.blobs['data'].reshape(net_batch_size, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "with lmdb_env.begin() as txn:\n",
    "    out = np.empty((out_batch_size, net.blobs['fc1000'].data.shape[1]), dtype=net.blobs['fc1000'].data.dtype)\n",
    "    images = np.empty((out_batch_size, 3, 256, 256), dtype=np.uint8)\n",
    "    datum = caffe_pb2.Datum()\n",
    "    \n",
    "    center_slice = slice(16, 256-16)\n",
    "    i = 0\n",
    "    cnt = 0\n",
    "    n_entry = 1\n",
    "    offset = 0\n",
    "#    print('No of imgs in db:',txn.stat()['entries'])\n",
    "    for key, value in txn.cursor(): \n",
    "\n",
    "        # load image\n",
    "        datum.ParseFromString(value)\n",
    "        img = caffe.io.datum_to_array(datum)            \n",
    "        images[i+offset] = img\n",
    "        \n",
    "        sys.stdout.write(\"img %d of \\r\" % (n_entry) )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "#        print(\"img {} of {}\".format(n_entry,txn.stat()['entries']) )\n",
    "#        print(\"net_batch {} of {}\".format(i+1, net_batch_size))\n",
    "#        print(\"offset {} of {}\".format(offset+1, out_batch_size))\n",
    "#        print(\"filling images at {}\".format(i+offset+1))\n",
    "        \n",
    "        # fills network with net_batch_size of images\n",
    "        net.blobs['data'].data[i,:,:,:] = img[:, center_slice, center_slice] - rgb_mean\n",
    "        \n",
    "        i += 1\n",
    "        # fowards the net everytime a net_batch is full\n",
    "        if i == net_batch_size:\n",
    "#            print(\"### Forward Net ###\")\n",
    "            i = 0\n",
    "            net.forward()\n",
    "            out[offset:(offset+net_batch_size)] = net.blobs['fc1000'].data[:]\n",
    "            offset += net_batch_size\n",
    "        # saves a hdf5 db everytime an out_batch is fully predicted\n",
    "        if offset == out_batch_size:\n",
    "            offset = 0\n",
    "#            print(\"### save hdf5 ###\")\n",
    "            with h5py.File(os.path.join(out_dir, \"batch_%04d.h5\" % cnt), \"w\") as f:\n",
    "                f.create_dataset('data', data=images, compression='gzip', dtype=np.uint8)\n",
    "                f.create_dataset('label', data=out, compression='gzip', dtype=net.blobs['fc1000'].data.dtype)\n",
    "            cnt += 1\n",
    "        n_entry += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
